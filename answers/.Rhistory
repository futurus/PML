beta0 = mean(y)-beta1*mean(x)
y-(x*beta1+beta0)
beta1
beta0
e=y-(x*beta1+beta0)
sigma = sqrt(sum(e^2)/(n-2))
sigma
sd(e)
ssx = sum((x-mean(x))^2)
seBeta0 = (1/n + mean(x)^2/ssx)^0.5*sigma
ssBeta1 = sigma/sqrt(ssx)
ssBeta1
ssBeta0
seBeta0
seBeta1 = ssBeta1
data(mtcars)
summary(lm(mpg ~ weight, data=mtcars))
mtcars
summary(lm(mpg ~ wt, data=mtcars))
?mtcars
predict(lm(mpg ~ wt, data=mtcars), data.frame(wt=mean(mtcars$wt))
predict(lm(mpg ~ wt, data=mtcars), data.frame(wt=mean(mtcars$wt)))
mean(mt$wt)
mean(mtcars$wt)
mean(mtcars$wt)*-5.3445 + 37.2851
fit = lm(mpg ~ wt, data=mtcars)
fit$df
sumCoef = summary(fit)$coef
sumCoef
sumCoef[1,1]
sumCoef[2,1]
sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2]
sumCoef[2, 2]
?qt
qt(.975, df = fit$df)
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fit$df) * sumCoef[2, 2])+20.09062
sigma
n
summary(fit)
ssx = sum((mtcars$wt - mean(mtcars$wt))^2)
ssx
se2 = sigma*sqrt(1 + 1/nrow(mtcars) + (mtcars$wt-mean(mtcars$wt))^2/ssx)
se2
se2 = sigma*sqrt(1 + 1/nrow(mtcars) + (mean(mtcars$wt)-mean(mtcars$wt))^2/ssx)
se2
20.09+c(-1,1)*2*se2
20.09+c(-1,1)*2.042272*se2
sigma*sqrt(1/nrow(mtcars) + (mean(mtcars$wt)-mean(mtcars$wt))^2/ssx)
se2 = sigma*sqrt(1 + 1/nrow(mtcars) + (3-mean(mtcars$wt))^2/ssx)
se2
20.09+c(-1,1)*2.042272*se2
lm(1:10 ~ 1:10)
b = 1:10
a = 1:10
lm(b ~ a)
lm(b ~ a+1)
a = a + 1
a
lm(b ~ a+1)
lm(b ~ a)
mtcars
fit1 = lm(mpg ~ wt, data=mtcars)
fit2 = lm(mpg ~ wt-1, data=mtcars)
summary(fit1)
summary(fit2)
plot(a, b)
plot(a+1, b)
plot(1:5, 1:%)
plot(1:5, 1:5)
point(2:6, 1:5)
points(2:6, 1:5)
data(mtcars)
fit = lm(mpg ~ wt, data=mtcars)
summary(fit)
sd(resid(fit))
3.046*sqrt(1+1/nrow(mtcars))
predict(fit, data.frame(wt=mean(mtcars)))
predict(fit, data.frame(wt=mean(mtcars$wt)))
se = 3.046*sqrt(1+1/nrow(mtcars))
predict(fit, data.frame(wt=mean(mtcars$wt)))-qt(.975, df=30)*se
predict(fit, data.frame(wt=mean(mtcars$wt)))-qt(.95, df=30)*se
se
qt(.975, df=30)
plot(wt, mpg, data=mtcars)
plot(mtcars$wt, mtcars$mpg)
abline(lm(mpg ~ wt, data=mtcars))
mean(mtcars$wt)
mean(mtcars$mpg)
xVals = seq(min(mtcars$wt), max(mtcars$wt), by = 0.1)
yVals = xVals * -5.3445 + 37.2851
ssx = sum((mtcars$wt - mean(mtcars$wt))^2)
ssx
se2 = 3.046 * sqrt(1 + 1/n + (xVals -mean(mtcars$wt))^2/ssx)
se2 = 3.046 * sqrt(1 + 1/nrow(mtcars) + (xVals -mean(mtcars$wt))^2/ssx)
lines(xVals, yVals + qt(.975, df=30)* se2)
lines(xVals, yVals - qt(.975, df=30)* se2)
summary(fit)
sumCoef = summary(fit)$coefficients
sumCoef
sumCoef[2, 1] + c(-1, 1)* qt(.975, df = 30) * sumCoef[2, 2]
-6.486*2
xVals
(yVals + qt(.975, df = 30)*se2)[16]
lines(xVals, mean(mtcars$mpg))
lines(xVals, rep(mean(mtcars$mpg), length(xVals)))
sum((mtcars$mpg - mean(mtcars$mpg))^2)
sum((resid(fit))^2)
sum((resid(fit))^2)/1126
mean(mtcars$wt)
(yVals + qt(.975, df = 30)*se2)[18]
(yVals - qt(.975, df = 30)*se2)[18]
(yVals - qt(.975, df = 30)*(sigma*sqrt(1/nrow(mtcars))))[18]
(yVals - qt(.975, df = 30)*(3.046*sqrt(1/nrow(mtcars))))[18]
(mean(mtcars$mpg) - qt(.975, df = 30)*(3.046*sqrt(1/nrow(mtcars))))
data = readline("http://biostat.jhsph.edu/~jleek/contact.html")
data = readline("http://biostat.jhsph.edu/~jleek/contact.html")
data = readLines("http://biostat.jhsph.edu/~jleek/contact.html")
data[1]
nchar(data[10])
nchar(data[20])
nchar(data[30])
nchar(data[100])
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
predictors
summary(predictors)
summary(diagnosis)
dim(diagnosis)
diagnosis
?createPartitionData
?createDataPartition
adData = data.frame(diagnosi, predictors)
adData = data.frame(diagnosis, predictors)
dim(predictors)
adData[1:10, ]
length(diagnosis)
trainIndex = createDataPartition(diagnosis, p=0.5)
trainIndex
trainIndex = createDataPartition(diagnosis, p=0.5, list=FALSE)
trainIndex
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
mixtures[1:5,]
qplot(1:nrow(mixtures), CompressiveStrength, data=mixtures)
mixtures$FlyAsh
qplot(mixtures$FlyAsh)
colnames(mixtures)
qplot(1:nrow(mixtures), CompressiveStrength, data=training)
qplot(1:nrow(training), CompressiveStrength, data=training)
qplot(1:nrow(CompressiveStrength), CompressiveStrength, data=testing)
qplot(1:nrow(testing), CompressiveStrength, data=testing)
qplot(1:nrow(training), CompressiveStrength, data=training)
qplot(1:nrow(training), CompressiveStrength, data=training, color=Cement)
qplot(1:nrow(training), CompressiveStrength, data=training, color=BlastFurnaceSlag)
qplot(1:nrow(training), CompressiveStrength, data=training, color=FlyAsh)
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=5))
library(Hmisc)
install.packages("Hmisc")
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=5))
library(Hmisc)
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=5))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=3))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=2))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=1))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=6))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=7))
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=8))
?cut2
summarize(training$FlyAsh)
summary(training$FlyAsh)
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=5))
histogram(mixtures$CompressiveStrength)
qplot(1:nrow(training), CompressiveStrength, data=training, color=cut2(training$FlyAsh, g=5))
View(training)
qplot(1:nrow(training), FlyAsh, data=training)
colnames(training)
qplot(1:nrow(training), Cement, data=training)
qplot(1:nrow(training), BlastFurnaceSlag, data=training)
qplot(1:nrow(training), Water, data=training)
qplot(1:nrow(training), Superplasticizer, data=training)
qplot(1:nrow(training), CoarseAggregate, data=training)
qplot(1:nrow(training), FineAggregate, data=training)
qplot(1:nrow(training), Age, data=training)
histogram(training$Superplasticizer)
histogram(log(training$Superplasticizer))
histogram(log(training$Superplasticizer)_1)
histogram(log(training$Superplasticizer)+1)
summary(training$Superplasticizer)
qplot(Superplasticizer, data=training, geom="density")
qplot(log(Superplasticizer), geom="density")
qplot(log(training$Superplasticizer), geom="density")
qplot(log(training$Superplasticizer+1), geom="density")
log(training$Superplasticizer)
log(training$Superplasticizer+1)
histlog(training$Superplasticizer)
hist(log(training$Superplasticizer))
log(training$Superplasticizer)
hist(log(training$Superplasticizer+1))
qplot(log(training$Superplasticizer), geom="density")
qplot(log(training$Superplasticizer+1), geom="density")
qplot(training$Superplasticizer, geom="density")
summary(training$Superplasticizer)
summary(log(training$Superplasticizer))
summary(log(training$Superplasticizer+1))
log(0.05)
log(1.05)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
colnames(predictors)
which(colnames(predictors) == "IL")
which(colnames(predictors) == "IL*")
ILs = 57:68
ILs
length(ILs)
?preProcess
preProc = preProcess(training[ , ILs], method="pca")
preProc
preProc = preProcess(training[ , ILs], method="pca", thresh=.80)
preProc
mydata = training[, c(1, ILs)]
summary(mydata)
colnames(training)
ILs
ILs = ILs[-1]
ILs
preProc = preProcess(training[ , ILs], method="pca", thresh=.80)
preProc
ILs = c(ILs, 69)
ILs
colnames(training)[ILs]
preProc = preProcess(training[ , ILs], method="pca", thresh=.80)
preProc
mydata = training[ , c(1, ILs)]
PCA = preProcess(mydata, method="pca", thresh=0.8)
PCA = preProcess(mydata[ , -1], method="pca", thresh=0.8)
PCA
PCAres = predict(PCA, mydata)
PCAres = predict(PCA, mydata[ , -1])
modelFitPCA = train(mydata$diagnosis ~. , method = "glm", data=PCAres)
install.packages("e1071")
modelFitPCA = train(mydata$diagnosis ~. , method = "glm", data=PCAres)
mytest = testing[ ,c(1, ILs)]
testPC = predict(PCA, mytest[ , -1])
confusionMatrix(mytest$diagnosis, predict(modelFitPCA, testPC))
PCAres
preProc
modelFitPCA
predict(modelFitPCA, testPC)
dim(PCAres)
head(PCAres)
modelFit = train(training$diagnosis ~ ., method="glm", data=training[ , -1])
warnings()
confusionMatrix(testing$diagnosis, predict(modelFit, testing[ , -1]))
modelFit = train(diagnosis ~ ., data=training, method="glm")
head(mydata)
mytrain = mydata
head(mydtest)
head(mytest)
modelFit = train(mytrain$diagnosis ~ ., method="glm", preProcess = "pca", data= mytrain)
confusionMatrix(mytest$diagnosis, predict(modelFit, mytest))
modelFit = train(mytrain$diagnosis ~ ., method="glm", data= mytrain)
confusionMatrix(mytest$diagnosis, predict(modelFit, mytest))
modelFit = train(mytrain$diagnosis ~ ., method="glm", preProcess = "pca", data= mytrain, thresh=0.8)
?train
preProc
modelFit = train(mytrain$diagnosis ~ ., method="glm", preProcess = preProc, data= mytrain, thresh=0.8)
modelFit = train(mytrain$diagnosis ~ ., method="glm", preProcess = preProc, data= mytrain)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(975)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
sapply(training[,1:8],cut2,g=4) -> training[,1:8]
training
qplot(1:nrow(training), training$CompressiveStrength)
qplot(1:nrow(training), training$CompressiveStrength, color=training$Cement)
par(mfrow = c(4, 2))
qplot(1:nrow(training), training$CompressiveStrength, color=training$Cement)
plot(1:nrow(training), training$CompressiveStrength, color=training$Cement)
str(trainig)
str(training)
par(mfcol=c(2,4))
for (i in 1:8) {plot(training$CompressiveStrength,main=names(training[i]),xlab="stepwise index",ylab="CompressiveStrength",col=training[,i])}
training$Cement
qplot(1:nrow(training), training$CompressiveStrength, color=training$Cement)
colnames(training)
qplot(1:nrow(training), training$CompressiveStrength, color=training$Age)
qplot(1:nrow(training), training$CompressiveStrength, color=training$FineAggregate)
qplot(1:nrow(training), training$CompressiveStrength, color=training$FlyAsh)
qplot(1:nrow(training), training$CompressiveStrength, color=training$Age)
summary(training$Age)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
colnames(training)
ILs = 58:69
colnames(training)[ILs]
mytrain = training[ ,c(1, ILs)]
preProcess(mytrain[ , -1], method = "pca", thresh=0.9)
library(knitr)
?knit2html
1100 + c(-1,1) * qt(0.975, 8) * 30/sqrt(9)
-2 + c(-1,1) * qt(0.975, 8) * 1.5/sqrt(9)
-2 + c(1) * qt(0.975, 8) * 1.5/sqrt(9)
-2 + c(1) * qt(0.975, 8) * 2.1/sqrt(9)
-2 + c(1) * qt(0.975, 8) * 2.5/sqrt(9)
-2 + c(1) * qt(0.975, 8) * 2.6/sqrt(9)
sp = (9 * 0.6^2 + 9 * 0.68^2)/(9+9-2)
sp
3 - 5 + c(-1, 1) *qt(0.975, 18) * sp * (1/9 + 1/9)^.5
sp = (9 * 0.6^2 + 9 * 0.68^2)/(20-2)
3 - 5 + c(-1, 1) *qt(0.975, 18) * sp * (1/9 + 1/9)^.5
df = (0.6/10 + 0.68/10)^2/(((0.6/10)^2)/9 + ((0.68/10)^2)/9)
df
3 - 6 + c(-1, 1) * qt(0.975, df) * (0.6/10 + 0.68/10)^0.5
3 - 5 + c(-1, 1) * qt(0.975, df) * (0.6/10 + 0.68/10)^0.5
3 - 5 + c(-1, 1) * qt(0.95, df) * (0.6/10 + 0.68/10)^0.5
df = (0.5/100 + 2/100)^2/(((0.5/100)^2)/99 + ((2/100)^2)/99)
6 - 4 + c(-1, 1) * qt(0.975, df) * (0.5/100 + 2/10)^0.5
4 - 6 + c(-1, 1) * qt(0.975, df) * (0.5/100 + 2/10)^0.5
sp = (8 * 1.5^2 + 8 * 1.8^2)/(9+9-2)
-3 - 1 + c(-1, 1) *qt(0.95, 9+9-2) * sp * (1/9 + 1/9)^.5
-3 - 1 + c(-1, 1) *qt(0.95, 9+9-2) * sp^0.5 * (1/9 + 1/9)^.5
data(mtcars)
colnames(mtcars)
fit = lm(mpg ~ cyl + wt, data=mtcars)
summary(fit)
4*-1.5078
fit = lm(mpg ~ factor(cyl) + wt, data=mtcars)
summary(fit)
factor(mtcars$cyl)
I
summary(lm(mpg ~ I(wt*0.5) + factor(cyl), data=mtcars))
fit2<-lm(mpg ~ cyl +wt, data=mtcars)
mycol=rainbow(8)
plot(mtcars$wt, mtcars$mpg, pch=19, col=mycol[mtcars$cyl])
abline(c(fit2$coeff[1],fit2$coeff[4]),col="red",lwd=3)
abline(c(fit2$coeff[1] + fit2$coeff[2] ,fit2$coeff[4]),col="blue",lwd=3)
abline(c(fit2$coeff[1] + fit2$coeff[3] ,fit2$coeff[4]),col="black",lwd=3)
fit = lm(mpg ~ factor(cyl) + wt, data=mtcars)
summary(fit)
fit = lm(mpg ~ factor(cyl), data=mtcars)
summary(fit)
?I
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
z = mtcars$wt*0.5
lm(mpg ~ z + factor(cyl), data = mtcars)
lm(mpg ~ wt * 0.5 + factor(cyl), data = mtcars)
lm(mpg ~ wt + factor(cyl), data = mtcars)
z
mtcars$wt
lm(mpg ~ wt * 0.5, data = mtcars)
lm(mpg ~ wt, data = mtcars)
lm(mpg ~ I(wt*0.5), data = mtcars)
plot(mtcars$wt, mtcars$mpg)
points(mtcars$wt*0.5, mtcars$mpg)
plot(mtcars$wt, mtcars$mpg, xlim =c(0, 6))
points(mtcars$wt*0.5, mtcars$mpg)
points(mtcars$wt*0.5, mtcars$mpg, xlim=c(0, 5))
plot(mtcars$wt, mtcars$mpg, xlim =c(0, 6))
points(mtcars$wt*0.5, mtcars$mpg, xlim=c(0, 5))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
lm(y ~ x)
lm.influence(lm(y ~ x))
x
y
hat(lm(y ~ x))
fit1 = lm(mpg ~ factor(cyl) + wt, data=mtcars)
fit2 = lm(mpg ~ factor(cyl) + wt + interaction(cyl, wt), data=mtcars)
summary(fit1)
summary(fit2)
summary(lm(mpg ~ factor(cyl), data=mtcars))
plot(mtcars$cyl, mtcars$mpg)
summary(lm(mpg ~ cyl, data=mtcars))
mean(mtcars$mpg[mtcars$cyl==4])
mean(mtcars$mpg[mtcars$cyl==6])
mean(mtcars$mpg[mtcars$cyl==4])-19.74286
mean(mtcars$mpg[mtcars$cyl==8])
anova(fit1, fit2)
?anova
data(AirPassengers)
AirPassengers
plot(AirPassengers)
data(ChickWeight)
ChickWeight
summary(ChickWeight)
require(graphics)
coplot(weight ~ Time | Chick, data = ChickWeight,
type = "b", show.given = FALSE)
ChickWeight$Chick
ChickWeight[which(ChickWeight$Chick==1),]
ChickWeight[which(ChickWeight$Chick==12),]
ChickWeight[which(ChickWeight$Chick==4),]
ChickWeight[which(ChickWeight$Chick==18),]
ChickWeight[which(ChickWeight$Chick==48),]
aggregate(ChickWeight, by=list(Diet), fun=mean)
aggregate(ChickWeight, by=list(Diet), FUN=mean)
aggregate(ChickWeight, by=list(Diet=ChickWeight$Diet), FUN=mean)
library(ggplot2)
qplot(Time, weight, data=ChickWeight, color=Diet)
qplot(Time, weight, data=ChickWeight, color=Diet) + geom_line()
View(ChickWeight)
qplot(Time, weight, data=ChickWeight, color=Diet) + geom_smooth()
ChickWeight[which(ChickWeight$Diet==1)]
ChickWeight[which(ChickWeight$Diet==1), ]
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet==1)], color=Diet) + geom_smooth()
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet==1),], color=Diet) + geom_smooth()
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet==1),], color=Diet) + geom_smooth(method="loess")
?geom_smooth
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet==1),], color=Diet) + geom_segment()
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2)),], color=Diet) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2,4)),], color=Diet) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=Diet) + geom_smooth(method="loess")
cols = c("red", "green", "blue", "orange")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=1:4) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=cols) + geom_smooth(method="loess")
?qplot
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=Diet) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 4)),], color=Diet) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=Diet) + geom_smooth(method="loess")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(1, 2, 3, 4)),], color=Diet) + geom_smooth(method="lm")
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(4)),], color=Diet) + geom_smooth(method="lm")
fit = lm(weight ~ Time, data=ChickWeight[which(ChickWeight$Diet==4)], )
fit = lm(weight ~ Time, data=ChickWeight[which(ChickWeight$Diet == 4), ])
fit
summary(fit)
Diet4 = ChickWeight[which(ChickWeight$Diet == 4), ]
Diet4
Diet4[which(Diet4$Time == 21), ]
mean(Diet4[which(Diet4$Time == 21), ][ , 1])
Diet3 = ChickWeight[which(ChickWeight$Diet == 3), ]
mean(Diet3[which(Diet4$Time == 21), ][ , 1])
summary(fit)
summary(lm(weight ~ Time, data=ChickWeight[which(ChickWeight$Diet == 3), ]))
qplot(Time, weight, data=ChickWeight[which(ChickWeight$Diet %in% c(3, 4)),], color=Diet) + geom_smooth(method="lm")
library(UsingR)
install.packages("UsingR")
library(UsingR)
data(father.son)
str(father.son)
head(father.son)
t.test(father.son$sheight-father.son$fheight)
mean(father.son$sheight-father.son$fheight)
sd(father.son$sheight-father.son$fheight)
sqrt(1078)*mean(father.son$sheight-father.son$fheight)/sd(father.son$sheight-father.son$fheight)
qt(0.975, 1077)
?pt
pt(11.7885, 1077)
pt(1, 1077)
pt(0.95, 1077)
mean(father.son$sheight-father.son$fheight) + c(-1, 1)*qt(0.975, 1077)
mean(father.son$sheight-father.son$fheight) + c(-1, 1)*qt(0.975, 1077)*sd(father.son$sheight-father.son$fheight)
mean(father.son$sheight-father.son$fheight) + c(-1, 1)*qt(0.975, 1077)*sd(father.son$sheight-father.son$fheight)/sqrt(1078)
sfd = father.son$sheight-father.son$fheight
plot(sfd)
?replications
TR = read.csv("pml-training.csv")
TE = read.csv("pml-testing.csv")
setwd("~/DataScience/PracticalMachineLearning/Course Project")
TR = read.csv("pml-training.csv")
nNAs = apply(TR, 2, function(col) {
sum(is.na(col) | col == "")
})
TR = TR[ , -which(nNAs > 0.9 * length(TR$classe))]
TE = read.csv("pml-testing.csv")
TR = TR[ , -nearZeroVar(TR)]
library(caret)
TR = TR[ , -nearZeroVar(TR)]
TR = TR[ , !names(TR) %in% c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2",
"cvtd_timestamp", "new_window", "num_window")]
dim(TR)
fitCtrl = trainControl(method="cv", number = 10, verboseIter = F)
gbmFit = train(classe ~ ., data=TR, trControl = fitCtrl, verbose=F)
gbmFit
confusionMatrix(predict(gbmFit, TR), TR$classe)
predict(gbmFit, TE)
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
res = predict(gbmFit, TE)
setwd("~/DataScience/PracticalMachineLearning/Course Project/answers")
pml_write_files(res)
